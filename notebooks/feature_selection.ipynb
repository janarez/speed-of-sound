{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    " - In this notebook forward and backward selection methods are implemented.\n",
    " - The methods are run on models with already optimized hyperparameters.\n",
    " - The union of feature sets returned by each of these methods is considered to be the optimal selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Restore the splitted data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "%store -r y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_val\n",
    "%store -r y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Metrics function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 and rmse and AARD returning function\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def result_stats(actual, predicted):\n",
    "    \"\"\"\n",
    "    Returns r_2, rmse and AARD value for two arrays of equal length\n",
    "    \"\"\"\n",
    "    \n",
    "    r2 = r2_score(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error( actual, predicted ))\n",
    "    aard = (100 / len(actual)) * np.sum(np.abs((actual - predicted) / actual))\n",
    "    \n",
    "    return r2,rmse, aard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Restore optimal hyperparameters for SVM and random forest models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r svm_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r rf_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import the models__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR as SVM\n",
    "svm = SVM(gamma = \"auto\", **svm_params)    # gamma value is left at default; explicitly set to surpress warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "rf = RF(n_estimators = 20, **rf_params)    # use 20 estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection functions definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use 5 fold cross validation to evaluate model performance\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(left, right, best):\n",
    "    \"\"\"\n",
    "    This function performs forward feature selection.\n",
    "    It expects global variables for data: X_train and y_train.\n",
    "    The evaluated model must be assigned to global variable model.\n",
    "    Input parameters: empty list, list of all features, 10000 (large enough number).\n",
    "    Output: Prints RMSE for all evaluated feature sets, until RMSE stops improving.\n",
    "    \"\"\"\n",
    "    if len(right) == 0:\n",
    "        print(left, best)\n",
    "        return\n",
    "        \n",
    "    # currently most helpful feature\n",
    "    best_f = \"\"\n",
    "    \n",
    "    # look for next best feature\n",
    "    for f in right:\n",
    "        if left == []:\n",
    "            fs = [f]\n",
    "        else:\n",
    "            fs = left + [f]\n",
    "              \n",
    "        prediction = cross_val_predict(model, X_train[fs], y_train, cv=3)\n",
    "        _, rmse, _ = result_stats(prediction, y_train)\n",
    "        \n",
    "        # check if adding feature f improves the current best result\n",
    "        if rmse < best:\n",
    "            best = rmse\n",
    "            best_f = f\n",
    "    \n",
    "    # feature addition helped, add feature and call the function again on current feature set    \n",
    "    if best_f != \"\":\n",
    "        if left == []:\n",
    "            fs = [best_f]\n",
    "        else:\n",
    "            fs = left + [best_f]\n",
    "        right.remove(best_f)\n",
    "        print(\"RMSE: {0:.2f}; Features: {1}\".format(best,fs))\n",
    "        forward_feature_selection(fs, right, best)\n",
    "        return\n",
    "    # no additional features can be added  \n",
    "    else:\n",
    "        print(\"RMSE: {0:.2f}; Features: {1}\".format(best,left))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_feature_selection(features, best):\n",
    "    \"\"\"\n",
    "    This function performs backward feature selection.\n",
    "    It expects global variables for data: X_train and y_train.\n",
    "    The evaluated model must be assigned to global variable model.\n",
    "    Input parameters: list of all features, 10000 (large enough number).\n",
    "    Output: Prints RMSE for all evaluated feature sets, until RMSE stops improving.\n",
    "    \"\"\"\n",
    "    if len(features) == 0:\n",
    "        return\n",
    "    \n",
    "    # currently least helpful feature\n",
    "    worst_f = \"\"\n",
    "    \n",
    "    # look for next worst feature\n",
    "    for f in features:\n",
    "        fs = features.copy()\n",
    "        fs.remove(f)\n",
    "              \n",
    "        prediction = cross_val_predict(model, X_train[fs], y_train, cv=3)\n",
    "        _, rmse, _ = result_stats(prediction, y_train)\n",
    "        \n",
    "        # check if removing feature f improves the current best result\n",
    "        if rmse < best:\n",
    "            best = rmse\n",
    "            worst_f = f\n",
    "    \n",
    "    # feature removal helped, remove feature and call the function again on current feature set\n",
    "    if worst_f != \"\":\n",
    "        features.remove(worst_f)\n",
    "        print(\"RMSE: {0:.2f}; Features: {1}\".format(best,features))\n",
    "        backward_feature_selection(features, best)\n",
    "        return\n",
    "    # no additional features can be removed  \n",
    "    else:\n",
    "        print(\"RMSE: {0:.2f}; Features: {1}\".format(best,features))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection on SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model variable\n",
    "model = svm\n",
    "svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(X_train.columns).copy()\n",
    "forward_feature_selection([], all_features,10000)\n",
    "# save the result\n",
    "forward = set(X_train.columns) - set(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(X_train.columns).copy()\n",
    "backward_feature_selection(all_features, 10000)\n",
    "# save the result\n",
    "backward = set(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimized feature set\n",
    "# final feature set is union of feature sets obtained through backward and forward selection\n",
    "svm_features = list(forward & backward)\n",
    "print(\"The optimized feature set for SVM: {0}\".format(svm_features))\n",
    "%store svm_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection on random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model variable\n",
    "model = rf\n",
    "# must reset the max_features hyperparameter from the optimized value back to all features\n",
    "rf.set_params(max_features = \"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(X_train.columns).copy()\n",
    "forward_feature_selection([], all_features,10000)\n",
    "# save the result\n",
    "forward = set(X_train.columns) - set(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = list(X_train.columns).copy()\n",
    "backward_feature_selection(all_features, 10000)\n",
    "# save the result\n",
    "backward = set(all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Optimization of the max_features hyperparameter gives better results and as such feature selection is not used for the random forest model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
