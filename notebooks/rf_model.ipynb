{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization of random forest model\n",
    "\n",
    "In this notebook Bayesian hyperparameter optimization is performed for the random forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general dependencies\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# bayesian optimization dependencies\n",
    "\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from skopt.utils import use_named_args\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings in this notebook\n",
    "# not necessary, can be commented\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Restore the splitted data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train\n",
    "%store -r y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_val\n",
    "%store -r y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Metrics function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2 and rmse and AARD returning function\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "def result_stats(actual, predicted):\n",
    "    \"\"\"\n",
    "    Returns r_2, rmse and AARD value for two arrays of equal length\n",
    "    \"\"\"\n",
    "    \n",
    "    r2 = r2_score(actual, predicted)\n",
    "    rmse = np.sqrt(mean_squared_error( actual, predicted ))\n",
    "    aard = (100 / len(actual)) * np.sum(np.abs((actual - predicted) / actual))\n",
    "    \n",
    "    return r2,rmse, aard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import the random forest model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "rf = RF(n_estimators=20)     # use 20 estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of the searched hyperparameter space\n",
    "space  = [\n",
    "          Integer(1,10, name='max_depth'),\n",
    "          Integer(3,10, name='min_samples_leaf'),\n",
    "          Integer(1,len(X_train.columns), name='max_features')\n",
    "         ]\n",
    "\n",
    "# global variable for printing the current call number\n",
    "run = 0\n",
    "\n",
    "@use_named_args(space)\n",
    "\n",
    "# function returning rmse on validation data for given hyperparameter configuration\n",
    "def objective(**params):\n",
    "    rf.set_params(**params)\n",
    "    \n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_val)\n",
    "    _, rmse, _ = result_stats(rf_pred, y_val)\n",
    "    \n",
    "    global run\n",
    "    run += 1\n",
    "    print(\"Run #{0}: {1:.2f}; {2}\".format(run, rmse, params))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Bayesian optimization for 50 configurations\n",
    "bayes = gp_minimize(objective, space, n_calls=50, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the best achieved results\n",
    "print(\"Top 10 results\")\n",
    "print(\"-------------------------\")\n",
    "\n",
    "results = [(rmse, run + 1) for run,rmse in enumerate(bayes.func_vals)]\n",
    "results.sort()\n",
    "\n",
    "for r in results[:10]:\n",
    "    print(\"RMSE {0:.2f} in run {1}\".format(r[0], r[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how the search converged towards minimum rmse\n",
    "plot_convergence(bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__NOTE:__ Because hyperparameter optimization for random forest model is quick, it is advisable to rerun the optimization several times, to minimize change of getting stuck in local minima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimal hyperparameters\n",
    "# the results might vary depending on the train/test split of the shuffled data\n",
    "# this has to be manually typed\n",
    "\n",
    "rf_params = {'max_depth': 10, 'min_samples_leaf': 3, 'max_features': 13}\n",
    "\n",
    "%store rf_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
